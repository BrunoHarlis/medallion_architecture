{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "239ea925-7bc0-472f-92f6-46fa01bc0bec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, current_timestamp, max\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25860ec3-38c4-45f1-93f4-8541d3517aea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def tables_of_schema(catalog_name):\n",
    "    table_name_df = spark.sql(f\"\"\"\n",
    "        SELECT table_name\n",
    "        FROM zz_bronze_{catalog_name}.information_schema.tables\n",
    "        WHERE table_schema = 'default'\n",
    "        ORDER BY table_name\n",
    "    \"\"\")\n",
    "\n",
    "    table_list = [row['table_name'] for row in table_name_df.collect()]\n",
    "    return table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "957afca9-4039-4b8d-83fd-095f9b0de48e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "integrity_schema = StructType([\n",
    "                StructField('nome_schema', StringType(), True),\n",
    "                StructField('nome_table', StringType(), True),\n",
    "                StructField('qtd_raw', IntegerType(), True),\n",
    "                StructField('qtd_bronze', IntegerType(), True),\n",
    "                StructField('nome_catalog', StringType(), True)\n",
    "            ])\n",
    "\n",
    "integrity_df = spark.createDataFrame([], integrity_schema)\n",
    "\n",
    "catalog_list = ['area_1', 'area_2', 'area_3']\n",
    "\n",
    "for catalog in catalog_list:\n",
    "    table_list = tables_of_schema(catalog)\n",
    "    for table in table_list:\n",
    "        df = spark.table(f'zz_bronze_{catalog}.default.{table}')\n",
    "        df = df.withColumn('nome_catalog', lit(catalog))\n",
    "\n",
    "        integrity_df = integrity_df.union(df)\n",
    "\n",
    "integrity_df = integrity_df.withColumn('data', current_timestamp())\n",
    "integrity_df.write.mode('append').saveAsTable('controle.integridade.integridade_raw_bronze')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "union_integrity_table",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
